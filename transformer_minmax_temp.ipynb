{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "dQOg7MWhTjoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensure Colab can use necessary libraries"
      ],
      "metadata": {
        "id": "BDvrCJxaVbTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna torch torchvision torchaudio scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMnQiyrzVaPg",
        "outputId": "ed149d10-6123-4c60-a10d-7950b560f57f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.16.4-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.16.4-py3-none-any.whl (247 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.0/247.0 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alembic, optuna, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed alembic-1.16.4 colorlog-6.9.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 optuna-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Colab imports"
      ],
      "metadata": {
        "id": "N330ffYcTpUh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVhEXgS0R8dn",
        "outputId": "2274db26-6bf3-4ab3-9ce3-eef5ae628353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/MyDrive/Internal Project Sp25/Summer Docs/Files')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Standard imports"
      ],
      "metadata": {
        "id": "rGd5KHZDTqfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, Dataset, Subset"
      ],
      "metadata": {
        "id": "KSyslm5VSVAb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data"
      ],
      "metadata": {
        "id": "hiIoDGkxTyQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('berkeley_decade_weather_data.csv', parse_dates=[\"date\"], index_col=\"date\")"
      ],
      "metadata": {
        "id": "6rUfOmVlSeXf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "aME0WoNXT1zT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sinusoidal encoding of day of year"
      ],
      "metadata": {
        "id": "hlMqeDV0T5GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sinusoidal_encode(df):\n",
        "    \"\"\"\n",
        "    Create day of year feature. Represent via sine/cosine transformation to preserve cyclical nature of days of year.\n",
        "    \"\"\"\n",
        "    df = df.copy()\n",
        "    df.index = pd.to_datetime(df.index, dayfirst=True)\n",
        "\n",
        "    day_of_year = df.index.dayofyear\n",
        "    is_leap_year = df.index.is_leap_year\n",
        "    days_in_year = np.where(is_leap_year, 366, 365)\n",
        "    normalized_day = day_of_year / days_in_year\n",
        "\n",
        "    df['sin_day'] = np.sin(2 * np.pi * normalized_day)\n",
        "    df['cos_day'] = np.cos(2 * np.pi * normalized_day)\n",
        "\n",
        "    return df\n",
        "\n",
        "\n",
        "encoded_df = sinusoidal_encode(df)"
      ],
      "metadata": {
        "id": "i8QD0ZvhSjSS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define target and exogenous columns. Scale exogeneous columns (all are continuous)"
      ],
      "metadata": {
        "id": "T0beMGKdT9yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_cols = ['temperature_max', 'temperature_min']\n",
        "exog_cols = ['precipitation_total', 'temperature_morning', 'temperature_afternoon', 'temperature_night', 'temperature_evening', 'cloud_cover_afternoon', 'humidity_afternoon', 'sin_day', 'cos_day']\n",
        "input_cols = target_cols + exog_cols\n",
        "\n",
        "y_scaler = StandardScaler()\n",
        "y_scaled = pd.DataFrame(y_scaler.fit_transform(encoded_df[target_cols]), columns=target_cols, index=df.index)\n",
        "\n",
        "X_scaler = StandardScaler()\n",
        "X_scaled = pd.DataFrame(X_scaler.fit_transform(encoded_df[exog_cols]), columns=exog_cols, index=df.index)\n",
        "\n",
        "df_scaled = pd.concat([y_scaled, X_scaled], axis=1)"
      ],
      "metadata": {
        "id": "Ri3aE3WLSkMb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(data, target_cols, exog_cols, seq_len, forecast_len):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_len - forecast_len):\n",
        "        past_target = data[i:i+seq_len][target_cols].values\n",
        "        past_exog = data[i:i+seq_len][exog_cols].values\n",
        "        future_target = data[i+seq_len:i+seq_len+forecast_len][target_cols].values\n",
        "        X.append(np.hstack([past_target, past_exog]))  # shape: seq_len x (target+exog)\n",
        "        y.append(future_target)  # shape: forecast_len x target_dim\n",
        "    return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "5sxS7yjzVttS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "metadata": {
        "id": "-CAPL-wiVyvc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TimeSeriesTransformer(nn.Module):\n",
        "    def __init__(self, input_dim, d_model, nhead, num_layers, forecast_len, output_dim):\n",
        "        super().__init__()\n",
        "        self.forecast_len = forecast_len\n",
        "        self.input_proj = nn.Linear(input_dim, d_model)\n",
        "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, batch_first=True)\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.output_proj = nn.Linear(d_model, forecast_len * output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.input_proj(x)\n",
        "        x = self.transformer(x)\n",
        "        x = x.mean(dim=1)  # Global average pooling\n",
        "        x = self.output_proj(x)\n",
        "        return x.view(x.shape[0], self.forecast_len, -1)"
      ],
      "metadata": {
        "id": "-DI2bmRwV18j"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEQ_LEN = 7\n",
        "FORECAST_LEN = 1\n",
        "\n",
        "X, y = create_sequences(df_scaled, target_cols, exog_cols, SEQ_LEN, FORECAST_LEN)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "9RKLABDOV8IR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n",
        "def objective(trial):\n",
        "    choices = [\n",
        "        (64, 2), (64, 4), (64, 8),\n",
        "        (128, 2), (128, 4), (128, 8),\n",
        "        (256, 4), (256, 8)\n",
        "    ]\n",
        "    d_model, nhead = trial.suggest_categorical(\"d_model_nhead\", choices)\n",
        "    num_layers = trial.suggest_int(\"num_layers\", 1, 4)\n",
        "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-2, log=True)\n",
        "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
        "    n_epochs = trial.suggest_int(\"n_epochs\", 10, 50)\n",
        "\n",
        "    dataset = TimeSeriesDataset(X_train, y_train)\n",
        "    val_losses = []\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    for train_idx, val_idx in tscv.split(X_train):\n",
        "        train_loader = DataLoader(Subset(dataset, train_idx), batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
        "        val_loader = DataLoader(Subset(dataset, val_idx), batch_size=batch_size, num_workers=2, pin_memory=True)\n",
        "\n",
        "        model_copy = TimeSeriesTransformer(\n",
        "            input_dim=X_train.shape[2],\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            num_layers=num_layers,\n",
        "            forecast_len=FORECAST_LEN,\n",
        "            output_dim=len(target_cols)\n",
        "        )\n",
        "        optimizer = torch.optim.Adam(model_copy.parameters(), lr=lr)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        model_copy.train()\n",
        "        for epoch in range(n_epochs):\n",
        "            for xb, yb in train_loader:\n",
        "                pred = model_copy(xb)\n",
        "                loss = criterion(pred, yb)\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "        model_copy.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                pred = model_copy(xb)\n",
        "                all_preds.append(pred.cpu().numpy())\n",
        "                all_targets.append(yb.cpu().numpy())\n",
        "\n",
        "        all_preds = np.concatenate(all_preds)\n",
        "        all_targets = np.concatenate(all_targets)\n",
        "        val_loss = np.mean((all_preds - all_targets)**2)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "    return np.mean(val_losses)\n",
        "\n",
        "study = optuna.create_study(direction=\"minimize\")\n",
        "study.optimize(objective, n_trials=5)\n",
        "\n",
        "print(\"Best parameters:\", study.best_params)\n",
        "print(\"Best validation MSE:\", study.best_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaTg3YwqWEDs",
        "outputId": "bc962c07-a708-4199-bcc1-2501d037bd34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-02 17:49:06,657] A new study created in memory with name: no-name-8067c3f0-e74f-4cd5-b1fd-c26a90558b51\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 2) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 8) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 2) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 8) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 8) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "[I 2025-08-02 17:56:36,022] Trial 0 finished with value: 0.3995414078235626 and parameters: {'d_model_nhead': (128, 8), 'num_layers': 3, 'lr': 3.448040266285779e-05, 'batch_size': 32, 'n_epochs': 19}. Best is trial 0 with value: 0.3995414078235626.\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 2) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (64, 8) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 2) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (128, 8) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 4) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "/usr/local/lib/python3.11/dist-packages/optuna/distributions.py:518: UserWarning: Choices for a categorical distribution should be a tuple of None, bool, int, float and str for persistent storage but contains (256, 8) which is of type tuple.\n",
            "  warnings.warn(message)\n",
            "[I 2025-08-02 18:09:06,691] Trial 1 finished with value: 0.4135200083255768 and parameters: {'d_model_nhead': (256, 4), 'num_layers': 4, 'lr': 4.257391847971217e-05, 'batch_size': 32, 'n_epochs': 14}. Best is trial 0 with value: 0.3995414078235626.\n",
            "[I 2025-08-02 18:16:21,696] Trial 2 finished with value: 0.4026462435722351 and parameters: {'d_model_nhead': (64, 2), 'num_layers': 4, 'lr': 0.0001627254068249582, 'batch_size': 64, 'n_epochs': 25}. Best is trial 0 with value: 0.3995414078235626.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = study.best_params\n",
        "print(\"Best params:\", best_params)\n",
        "\n",
        "d_model, nhead = best_params[\"d_model_nhead\"]\n",
        "\n",
        "model = TimeSeriesTransformer(\n",
        "    input_dim=X_train.shape[2],\n",
        "    d_model=d_model,\n",
        "    nhead=nhead,\n",
        "    num_layers=best_params[\"num_layers\"],\n",
        "    forecast_len=FORECAST_LEN,\n",
        "    output_dim=len(target_cols)\n",
        ")\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=best_params[\"lr\"])\n",
        "criterion = nn.MSELoss()\n",
        "batch_size = best_params[\"batch_size\"]\n",
        "n_epochs = best_params.get(\"n_epochs\", 30)\n",
        "\n",
        "train_loader = DataLoader(TimeSeriesDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(n_epochs):\n",
        "    for xb, yb in train_loader:\n",
        "        pred = model(xb)\n",
        "        loss = criterion(pred, yb)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluate on test set\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    preds = model(torch.tensor(X_test, dtype=torch.float32)).numpy()\n",
        "    y_true = y_test.reshape(-1, len(target_cols))\n",
        "    y_pred = preds.reshape(-1, len(target_cols))\n",
        "\n",
        "# Undo StandardScaler transformation\n",
        "y_true_unscaled = y_scaler.inverse_transform(y_true)\n",
        "y_pred_unscaled = y_scaler.inverse_transform(y_pred)\n",
        "\n",
        "mae = mean_absolute_error(y_true_unscaled, y_pred_unscaled)\n",
        "rmse = np.sqrt(mean_squared_error(y_true_unscaled, y_pred_unscaled))\n",
        "r2 = r2_score(y_true_unscaled, y_pred_unscaled)\n",
        "\n",
        "print(f\"Test MAE: {mae:.4f}\")\n",
        "print(f\"Test RMSE: {rmse:.4f}\")\n",
        "print(f\"Test R2: {r2:.4f}\")"
      ],
      "metadata": {
        "id": "0_Yfek8VWoQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/Internal Project Sp25/Summer Docs/Files/transformer_2\"\n",
        "\n",
        "torch.save(model.state_dict(), save_path)\n",
        "print(f\"Model saved to {save_path}\")"
      ],
      "metadata": {
        "id": "tLpyszKkv6B6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}